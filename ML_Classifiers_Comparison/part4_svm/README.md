# بخش ۴: تحلیل ماشین بردار پشتیبان (SVM)

## هدف
بررسی الگوریتم SVM با کرنل‌های مختلف و مقادیر متفاوت پارامتر C.

## SVM چیست؟
Support Vector Machine یک الگوریتم قدرتمند برای طبقه‌بندی است که:
- یک ابرصفحه (Hyperplane) برای جداسازی کلاس‌ها پیدا می‌کند
- سعی می‌کند حاشیه (Margin) بین کلاس‌ها را حداکثر کند
- از بردارهای پشتیبان (نقاط نزدیک به مرز) استفاده می‌کند

## آزمایش انجام شده

### بخش اول: SVM خطی با مقادیر مختلف C
مقادیر C تست شده: `[0.01, 0.1, 1, 10, 100]`

### بخش دوم: کرنل‌های مختلف
- **Linear**: برای داده‌های خطی جدایی‌پذیر
- **Polynomial (degree=3)**: برای روابط چندجمله‌ای
- **RBF (Radial Basis Function)**: برای روابط غیرخطی پیچیده

## پارامتر C چیست؟
C پارامتر تنظیم‌کننده (Regularization) است:
- کنترل تعادل بین Margin و خطای طبقه‌بندی
- تأثیر مستقیم بر Generalization مدل

### C کوچک (مثلاً 0.01)
```
✓ Margin بزرگ‌تر (Soft Margin)
✓ تحمل بیشتر برای خطاهای طبقه‌بندی
✓ Generalization بهتر
✗ ممکن است Underfitting رخ دهد
✗ دقت آموزش کمتر
```

### C بزرگ (مثلاً 100)
```
✓ Margin کوچک‌تر (Hard Margin)
✓ دقت آموزش بالا
✗ تحمل کمتر برای خطاها
✗ ممکن است Overfitting رخ دهد
✗ Generalization ضعیف‌تر
```

### C بهینه
```
✓ تعادل بین Margin و دقت
✓ بهترین Generalization
✓ عملکرد خوب روی داده‌های جدید
```

## کرنل‌ها

### Linear Kernel
```
K(x, y) = x · y
```
- ساده‌ترین کرنل
- مناسب داده‌های خطی جدایی‌پذیر
- سریع‌تر از سایر کرنل‌ها

### Polynomial Kernel
```
K(x, y) = (x · y + c)^d
```
- d = درجه چندجمله‌ای (در اینجا 3)
- می‌تواند روابط غیرخطی را مدل کند
- پیچیده‌تر از Linear

### RBF Kernel
```
K(x, y) = exp(-γ||x - y||²)
```
- انعطاف‌پذیرترین کرنل
- مناسب اکثر مسائل غیرخطی
- نیاز به تنظیم پارامتر γ

## تحلیل اثر C روی Margin و Generalization

### رابطه C و Margin
- C کوچک → Margin بزرگ → مدل ساده‌تر
- C بزرگ → Margin کوچک → مدل پیچیده‌تر

### رابطه C و Generalization
- C کوچک: بایاس بالا، واریانس پایین → ممکن است Underfit کند
- C بزرگ: بایاس پایین، واریانس بالا → ممکن است Overfit کند
- C بهینه: تعادل بین بایاس و واریانس

## ماتریس درهم‌ریختگی (Confusion Matrix)
برای هر مدل، ماتریس درهم‌ریختگی رسم شده که نشان می‌دهد:
- درایه (i, j): تعداد نمونه‌های کلاس i که به کلاس j طبقه‌بندی شده‌اند
- قطر اصلی: طبقه‌بندی صحیح
- خارج قطر: طبقه‌بندی اشتباه

## خروجی‌های کد
- `svm_analysis.png`: مقایسه دقت کرنل‌ها
- `svm_confusion_matrices.png`: ماتریس درهم‌ریختگی

## بهترین عملکرد
معمولاً RBF با C مناسب بهترین نتیجه را روی دیتاست digits می‌دهد.

## نحوه اجرا
```bash
python svm_analysis.py
```
