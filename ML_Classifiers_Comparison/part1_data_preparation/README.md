# بخش ۱: آماده‌سازی داده‌ها

## هدف
در این بخش، دیتاست `digits` از کتابخانه sklearn بارگذاری و برای استفاده در الگوریتم‌های یادگیری ماشین آماده می‌شود.

---

## پاسخ به سوالات تمرین

### گزارش اطلاعات دیتاست

| معیار | مقدار |
|-------|-------|
| **تعداد نمونه‌ها** | 1797 |
| **تعداد ویژگی‌ها** | 64 |
| **تعداد کلاس‌ها** | 10 (ارقام 0 تا 9) |

### تقسیم داده‌ها

| مجموعه | تعداد نمونه |
|--------|-------------|
| **آموزش (70%)** | 1257 |
| **آزمون (30%)** | 540 |

### دو حالت بررسی الگوریتم‌ها

1. **بدون نرمال‌سازی**: داده‌های خام با مقادیر پیکسل در بازه [0, 16]
2. **با StandardScaler**: داده‌های نرمال‌شده با میانگین 0 و انحراف معیار 1

---

## جزئیات فنی

### دیتاست Digits
- **تعداد نمونه‌ها**: ۱۷۹۷ تصویر از ارقام دست‌نویس ۰ تا ۹
- **تعداد ویژگی‌ها**: ۶۴ (تصاویر ۸×۸ پیکسل)
- **تعداد کلاس‌ها**: ۱۰ (ارقام ۰ تا ۹)

### بارگذاری دیتاست
```python
from sklearn.datasets import load_digits
digits = load_digits()
```

### تقسیم داده‌ها
داده‌ها به نسبت ۷۰٪ آموزش و ۳۰٪ آزمون تقسیم شده‌اند:
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
```

### نرمال‌سازی با StandardScaler
```python
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

### نرمال‌سازی چیست؟
StandardScaler هر ویژگی را به صورت زیر تبدیل می‌کند:
```
z = (x - μ) / σ
```
- `x`: مقدار اصلی
- `μ`: میانگین
- `σ`: انحراف معیار
- `z`: مقدار نرمال‌شده

### چرا نرمال‌سازی مهم است؟
- الگوریتم‌هایی مانند KNN و SVM از فاصله استفاده می‌کنند
- ویژگی‌های با مقیاس بزرگ‌تر تأثیر بیشتری دارند
- نرمال‌سازی باعث می‌شود همه ویژگی‌ها تأثیر برابر داشته باشند

## خروجی‌های کد
- `sample_digits.png`: نمونه‌ای از تصاویر ارقام
- `normalization_comparison.png`: مقایسه توزیع داده‌ها قبل و بعد از نرمال‌سازی

## نحوه اجرا
```bash
python data_preparation.py
```
