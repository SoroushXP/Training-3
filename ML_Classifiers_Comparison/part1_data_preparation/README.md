# بخش ۱: آماده‌سازی داده‌ها

## هدف
در این بخش، دیتاست `digits` از کتابخانه sklearn بارگذاری و برای استفاده در الگوریتم‌های یادگیری ماشین آماده می‌شود.

## دیتاست Digits
- **تعداد نمونه‌ها**: ۱۷۹۷ تصویر از ارقام دست‌نویس ۰ تا ۹
- **تعداد ویژگی‌ها**: ۶۴ (تصاویر ۸×۸ پیکسل)
- **تعداد کلاس‌ها**: ۱۰ (ارقام ۰ تا ۹)

## مراحل انجام شده

### ۱. بارگذاری دیتاست
```python
from sklearn.datasets import load_digits
digits = load_digits()
```

### ۲. تقسیم داده‌ها
داده‌ها به نسبت ۷۰٪ آموزش و ۳۰٪ آزمون تقسیم شده‌اند:
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
```

### ۳. نرمال‌سازی با StandardScaler
```python
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

## دو حالت بررسی
1. **بدون نرمال‌سازی**: داده‌های خام با مقادیر پیکسل ۰ تا ۱۶
2. **با StandardScaler**: داده‌های نرمال‌شده با میانگین ۰ و انحراف معیار ۱

## نرمال‌سازی چیست؟
StandardScaler هر ویژگی را به صورت زیر تبدیل می‌کند:
```
z = (x - μ) / σ
```
- `x`: مقدار اصلی
- `μ`: میانگین
- `σ`: انحراف معیار
- `z`: مقدار نرمال‌شده

## چرا نرمال‌سازی مهم است؟
- الگوریتم‌هایی مانند KNN و SVM از فاصله استفاده می‌کنند
- ویژگی‌های با مقیاس بزرگ‌تر تأثیر بیشتری دارند
- نرمال‌سازی باعث می‌شود همه ویژگی‌ها تأثیر برابر داشته باشند

## خروجی‌های کد
- `sample_digits.png`: نمونه‌ای از تصاویر ارقام
- `normalization_comparison.png`: مقایسه توزیع داده‌ها قبل و بعد از نرمال‌سازی

## نحوه اجرا
```bash
python data_preparation.py
```
