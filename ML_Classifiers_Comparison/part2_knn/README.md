# بخش ۲: تحلیل الگوریتم KNN

## هدف
بررسی الگوریتم K-Nearest Neighbors (KNN) برای مقادیر k از ۱ تا ۴۰ و یافتن مقدار بهینه k.

---

## پاسخ به سوالات تمرین

### نتایج آزمایش KNN برای k=1 تا k=40

| حالت | بهترین K | دقت (Accuracy) | خطا (Error) |
|------|----------|----------------|-------------|
| **با StandardScaler** | K=1 | 0.9741 (97.41%) | 0.0259 |
| **بدون نرمال‌سازی** | K=1 | 0.9870 (98.70%) | 0.0130 |

### تعیین K بهینه
**مقدار K بهینه: K=1** با بالاترین دقت روی داده‌های آزمون.

---

### تحلیل اثر مقدار k کوچک و بزرگ (Overfitting یا Underfitting)

**k کوچک (مثلاً k=1) → Overfitting:**
- مدل بیش از حد به داده‌های آموزش وفادار است
- بسیار حساس به نویز و داده‌های پرت (outliers)
- واریانس بالا، بایاس پایین
- چون فقط یک همسایه را در نظر می‌گیرد، ممکن است تصمیمات نادرستی بگیرد
- اگر آن یک همسایه یک نقطه نویزی باشد، نتیجه اشتباه می‌شود

**k بزرگ (مثلاً k=40) → Underfitting:**
- مدل بیش از حد ساده می‌شود
- به همسایگان دور که ممکن است به کلاس‌های دیگر تعلق داشته باشند نیز توجه می‌کند
- واریانس پایین، بایاس بالا
- مرز تصمیم‌گیری خیلی صاف (smooth) می‌شود و جزئیات را از دست می‌دهد
- همسایگان بی‌ربط ممکن است تأثیر منفی روی نتیجه داشته باشند

**چرا؟**
- k کوچک = پیچیدگی بالا = حفظ داده‌های آموزش = Overfitting
- k بزرگ = پیچیدگی پایین = نادیده گرفتن جزئیات = Underfitting
- k بهینه = تعادل بین واریانس و بایاس

---

### تفاوت نتایج با و بدون نرمال‌سازی

**توضیح:**
- KNN از فاصله اقلیدسی برای یافتن همسایگان استفاده می‌کند: `d(x,y) = √(Σ(xi - yi)²)`
- بدون نرمال‌سازی، ویژگی‌هایی که مقیاس بزرگ‌تری دارند، تأثیر بیشتری در محاسبه فاصله دارند
- نرمال‌سازی باعث می‌شود همه ویژگی‌ها تأثیر برابر داشته باشند

**در دیتاست Digits:**
- همه پیکسل‌ها در بازه [0, 16] هستند و مقیاس تقریباً یکسانی دارند
- به همین دلیل تفاوت چشمگیری بین حالت نرمال و غیرنرمال مشاهده نمی‌شود
- در دیتاست‌هایی که ویژگی‌ها مقیاس‌های متفاوتی دارند (مثلاً سن [0-100] و درآمد [0-1000000])، نرمال‌سازی تأثیر بسیار زیادی خواهد داشت

---

## جزئیات فنی

### الگوریتم KNN چیست؟
KNN یک الگوریتم یادگیری ماشین است که برای طبقه‌بندی یک نمونه جدید:
1. k نزدیک‌ترین همسایه را در داده‌های آموزش پیدا می‌کند
2. برچسب اکثریت همسایگان را به نمونه جدید اختصاص می‌دهد

## خروجی‌های کد
- `knn_analysis.png`: نمودار دقت و خطا بر حسب k
- نمایش بهترین k و دقت متناظر

## نحوه اجرا
```bash
python knn_analysis.py
```
