# بخش ۵: مقایسه نهایی مدل‌ها

## هدف
مقایسه جامع سه الگوریتم KNN، Decision Tree و SVM و انتخاب بهترین الگوریتم برای دیتاست digits.

## جدول مقایسه نهایی

| Algorithm | Best Parameters | Accuracy | Precision | Recall |
|-----------|----------------|----------|-----------|--------|
| KNN | K=? | ? | ? | ? |
| Decision Tree | max_depth=? | ? | ? | ? |
| SVM | kernel=?, C=? | ? | ? | ? |

*مقادیر واقعی با اجرای کد مشخص می‌شوند*

## معیارهای ارزیابی

### Accuracy (دقت)
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```
- نسبت پیش‌بینی‌های صحیح به کل پیش‌بینی‌ها
- معیار کلی عملکرد مدل

### Precision (دقت مثبت)
```
Precision = TP / (TP + FP)
```
- از بین موارد پیش‌بینی شده مثبت، چند درصد واقعاً مثبت بودند؟
- مهم وقتی هزینه False Positive بالاست

### Recall (یادآوری)
```
Recall = TP / (TP + FN)
```
- از بین موارد واقعاً مثبت، چند درصد را درست شناسایی کردیم؟
- مهم وقتی هزینه False Negative بالاست

### F1-Score
```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
```
- میانگین هارمونیک Precision و Recall
- تعادل بین دو معیار

## مقایسه الگوریتم‌ها

### KNN
**مزایا:**
- ساده و قابل فهم
- نیاز به آموزش ندارد (Lazy Learning)
- مناسب برای داده‌های کوچک

**معایب:**
- کند برای داده‌های بزرگ
- حساس به ابعاد بالا
- نیاز به انتخاب K مناسب

### Decision Tree
**مزایا:**
- قابل تفسیر و visualize
- سریع در پیش‌بینی
- نیاز به نرمال‌سازی ندارد

**معایب:**
- مستعد Overfitting
- حساس به تغییرات کوچک داده
- ممکن است درخت پیچیده شود

### SVM
**مزایا:**
- عملکرد عالی در ابعاد بالا
- مقاوم در برابر Overfitting
- انعطاف‌پذیر با کرنل‌های مختلف

**معایب:**
- کند برای داده‌های بزرگ
- نیاز به تنظیم پارامتر
- قابل تفسیر نیست

## کدام الگوریتم پیشنهاد می‌شود؟

### برای دیتاست Digits:
بر اساس نتایج آزمایش، **SVM با کرنل RBF** معمولاً بهترین عملکرد را دارد.

### دلایل:
1. **ابعاد بالای داده**: ۶۴ ویژگی → SVM در ابعاد بالا خوب کار می‌کند
2. **روابط غیرخطی**: کرنل RBF می‌تواند این روابط را مدل کند
3. **Margin حداکثر**: SVM تعمیم‌پذیری خوبی دارد
4. **مقاومت در برابر نویز**: با انتخاب C مناسب

### توصیه‌های عملی:
- برای سادگی و سرعت: **KNN** یا **Decision Tree**
- برای دقت بالا: **SVM**
- برای قابلیت تفسیر: **Decision Tree**

## خروجی‌های کد
- `comparison_results.csv`: جدول نتایج به صورت CSV
- `final_comparison.png`: نمودار مقایسه معیارها

## نتیجه‌گیری نهایی
انتخاب الگوریتم مناسب بستگی به:
- اندازه داده
- نیاز به تفسیرپذیری
- منابع محاسباتی
- اهمیت نسبی Precision و Recall

## نحوه اجرا
```bash
python final_comparison.py
```
